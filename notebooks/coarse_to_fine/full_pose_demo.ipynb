{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e140c587-f9b2-4d14-81a0-dd278b7f9138",
   "metadata": {},
   "source": [
    "## Full demo notebook for pose estimation \n",
    "**This notebook demonstrates the coarse-to-fine, bottom-up approach to pose estimation for an object with known identity.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f98afea-6c3b-40a7-bdfc-95e120595a0c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0ecb18-c16a-409a-843d-bfe8b21e7c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg\n",
    "Pkg.activate(\"../../\");  # setup InverseGraphics environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d41b1ef-e5ba-4e9f-b314-6829becaa52d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pkg.precompile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123c81a1-1ded-4495-8b5d-060a2399015c",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import Revise\n",
    "import GLRenderer as GL\n",
    "import Images as I\n",
    "import MiniGSG as S\n",
    "import Rotations as R\n",
    "import PoseComposition: Pose, IDENTITY_POSE, IDENTITY_ORN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2953c409-ced0-42e9-b765-ddfa8fec2e4c",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import InverseGraphics as T\n",
    "import NearestNeighbors\n",
    "import LightGraphs as LG\n",
    "import StaticArrays\n",
    "import ProgressMeter\n",
    "import Serialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff7eb14-43a8-4fc7-9117-e7475ab1a0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributions\n",
    "import Gen\n",
    "using ProgressMeter\n",
    "try\n",
    "    import MeshCatViz as V\n",
    "catch\n",
    "    import MeshCatViz as V    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95663fc1-f09b-4847-bf25-6d531c4fc492",
   "metadata": {},
   "outputs": [],
   "source": [
    "V.setup_visualizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81920d30-7d2b-4674-ae26-2598081a3122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YCB object models\n",
    "YCB_DIR = joinpath(dirname(dirname(pwd())),\"data\")\n",
    "world_scaling_factor = 10.0\n",
    "id_to_cloud, id_to_shift, id_to_box  = T.load_ycbv_models_adjusted(YCB_DIR, world_scaling_factor);\n",
    "all_ids = sort(collect(keys(id_to_cloud)));\n",
    "names = T.load_ycb_model_list(YCB_DIR);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3232bc-97f1-46dc-ba3e-f2fee3787257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the canera intrinsics and renderer that will render using those intrinsics.\n",
    "camera = GL.CameraIntrinsics()\n",
    "camera = T.scale_down_camera(camera, 5.5)\n",
    "camera_pose = IDENTITY_POSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f85458-e9d3-460b-bd9c-7492aa53c6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize renderer and load all ycb objects\n",
    "renderer = GL.setup_renderer(camera, GL.DepthMode())\n",
    "resolution = 0.05\n",
    "\n",
    "for id in all_ids\n",
    "    cloud = id_to_cloud[id]\n",
    "    mesh = GL.mesh_from_voxelized_cloud(GL.voxelize(cloud, resolution), resolution);\n",
    "    GL.load_object!(renderer, mesh)\n",
    "end\n",
    "@show length(all_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab130d3-c592-479c-9a00-7544204e1ed9",
   "metadata": {},
   "source": [
    "### Introductory visualizations\n",
    "Visual examples of coarse-to-fine rendering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b21fec0-7465-41db-a19f-8bd83fe00ac7",
   "metadata": {},
   "source": [
    "#### \"Radius\" ($r$ in likelihood) scaling\n",
    "$$p(Y \\vert \\textbf{O}^M, \\textbf{x}_v) = \\prod_{i=1}^{K} (C \\cdot \\frac{1}{B} + \\frac{1-C}{\\tilde{K}} \\sum_{j=1}^{\\tilde{K}}\\frac{\\mathbf{1} (\\vert\\vert{y_i - \\tilde{y_i}}\\vert\\vert  \\leq r)}{\\frac{4}{3}\\pi r^3}) \n",
    "\\label{equation:likelihood}$$\n",
    "\n",
    "\n",
    "\n",
    "Infinite mixture (for $K$, the # of points in the sampled cloud) of finite mixtures (each sphere centered at template cloud point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cfcb57-3eeb-446d-80b2-d4f3b9d40268",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = (-100.0, 100.0, -100.0, 100.0,-100.0, 100.0)  # world bounds\n",
    "\n",
    "sample_id = rand(all_ids)  # choose some object in all_ids\n",
    "@show names[sample_id]\n",
    "sample_pose = Pose([0.0, 0.0, 3.0], R.RotXYZ(0.4, -0.2, 0.4))  # and a random pose\n",
    "\n",
    "# Reset the intrinsics inside of the renderer.\n",
    "GL.set_intrinsics!(renderer, camera) \n",
    "\n",
    "# And render the same image as above.\n",
    "gt_depth_image = GL.gl_render(renderer, [sample_id], [sample_pose], camera_pose)\n",
    "IJulia.display(GL.view_depth_image(gt_depth_image))\n",
    "\n",
    "# Create point cloud corresponding to that rendered depth image.\n",
    "gt_cloud = GL.depth_image_to_point_cloud(gt_depth_image, camera);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245f1568",
   "metadata": {},
   "source": [
    "Try varying the radius between small (0.01) to large (10) and observe the sampled point cloud visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c0439e-3399-491f-a186-4580c6e9b467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# radius = 0.01 \n",
    "# radius = 0.1\n",
    "radius = 1.0\n",
    "# radius = 10.0\n",
    "\n",
    "sampled_cloud = T.voxelize(Gen.random(T.uniform_mixture_from_template, gt_cloud, 0.0001, radius, bounds), 0.005)\n",
    "\n",
    "# Visualize the point cloud.\n",
    "V.setup_visualizer()\n",
    "V.viz(sampled_cloud, color=I.colorant\"red\", channel_name=:origin)  # = V.viz(T.move_points_to_frame_b(c, camera_pose))\n",
    "\n",
    "\n",
    "function move_points_to_frame_b(points_in_frame_a::Matrix{<:Real}, b_relative_to_a::Pose)\n",
    "    if size(points_in_frame_a)[1] != 3\n",
    "        error(\"expected an 3 x n matrix\")\n",
    "    end\n",
    "    n = size(points_in_frame_a[2])\n",
    "    return b_relative_to_a.orientation * points_in_frame_a .+ b_relative_to_a.pos\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b0b61a",
   "metadata": {},
   "source": [
    "#### Camera downscaling\n",
    "Alternatively, we can downscale the camera resolution to generate depth images of different coarseness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477d1507",
   "metadata": {},
   "outputs": [],
   "source": [
    "using IJulia\n",
    "\n",
    "final = 6\n",
    "for downscale_factor=:3.0:final\n",
    "    println(\"scale down by $downscale_factor\")\n",
    "    \n",
    "    # scale camera according to resolution; reset renderer\n",
    "    scaled_camera = GL.scale_down_camera(camera, downscale_factor)\n",
    "        \n",
    "    # Set the renderer to now have those scaled down intrinsics.\n",
    "    GL.set_intrinsics!(renderer, scaled_camera)\n",
    " \n",
    "    d = GL.gl_render(renderer, [sample_id], [sample_pose], IDENTITY_POSE)\n",
    "\n",
    "    img = GL.view_depth_image(d)\n",
    "    img = I.imresize(img, (camera.height, camera.width));\n",
    "    IJulia.display(img)\n",
    "  \n",
    "    # revert intrinsics\n",
    "    GL.set_intrinsics!(renderer, camera)\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a779f931",
   "metadata": {},
   "source": [
    "### Enumerative inference setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109e1fe5",
   "metadata": {},
   "source": [
    "#### Cloud helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87b1b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generative model trace visualization\n",
    "function viz_trace(trace)\n",
    "    V.setup_visualizer()\n",
    "    V.viz(Gen.get_retval(trace).voxelized_cloud  ./ 10.0; color=I.colorant\"red\", channel_name=:gen);\n",
    "    V.viz(Gen.get_retval(trace).obs_cloud ./ 10.0; color=I.colorant\"blue\", channel_name=:obs);\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff608eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get point cloud from the object ids, object poses, and camera pose\n",
    "\n",
    "# Render and calculate pc\n",
    "function get_cloud_nocache(poses, ids)\n",
    "    depth_image = GL.gl_render(renderer, ids, poses, camera_pose)\n",
    "    cloud = GL.depth_image_to_point_cloud(depth_image, renderer.camera_intrinsics)\n",
    "    if isnothing(cloud)\n",
    "        cloud = zeros(3,1)\n",
    "    else\n",
    "        cloud = T.move_points_to_frame_b(cloud, camera_pose)\n",
    "    end\n",
    "    cloud\n",
    "end\n",
    "\n",
    "# Get cloud from cache\n",
    "function get_cloud_func_cached(p, id)\n",
    "    idx1 = argmin(sum((dirs .- (p.orientation * [1,0,0])).^2, dims=1))[2]\n",
    "    idx2 = argmin([abs(R.rotation_angle(inv(p.orientation) * r)) for r in rotations_to_enumerate_over[idx1,:]])\n",
    "    # closest_orientation = rotations_to_enumerate_over[idx1,idx2]\n",
    "    c = T.move_points_to_frame_b(cloud_lookup[id][idx1,idx2], p)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674cc8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate cached renderings of all objects at all rotations, positioned at reference frame\n",
    "function generate_cloud_cache()\n",
    "    cloud_lookup = []\n",
    "    @showprogress for id in all_ids\n",
    "        cloud = \n",
    "        [\n",
    "            let\n",
    "                position = [0.0, 0.0, 10.0]\n",
    "                pose = Pose(position, rotations_to_enumerate_over[i,j])\n",
    "                d = T.GL.gl_render(renderer, [id], [pose], IDENTITY_POSE);\n",
    "                c = T.GL.depth_image_to_point_cloud(d, camera)\n",
    "                c = T.get_points_in_frame_b(c, pose)  # gets the cloud in the render pose reference frame\n",
    "            end\n",
    "            for i = 1:size(rotations_to_enumerate_over,1), j = 1:size(rotations_to_enumerate_over,2)\n",
    "        ]\n",
    "        push!(cloud_lookup, cloud)    \n",
    "    end \n",
    "    \n",
    "    return cloud_lookup\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850dd395",
   "metadata": {},
   "source": [
    "#### Inference helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f106c2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "function precompute_enumerations(gt_voxelized_cloud, gt_pose, init_radius, renderer, first_candidate_obj, last_candidate_obj, rotations_to_enumerate_over)\n",
    "    # initialize a state of initial particles with various rotations\n",
    "    all_scored_traces = []\n",
    "    x, y, z = gt_pose.pos\n",
    "    gt_position = [x,y,z]\n",
    "    @Threads.threads for obj_id=first_candidate_obj:last_candidate_obj\n",
    "        scored_traces = map(orn -> \n",
    "                        Gen.generate(model, (init_radius, renderer, gt_position),                 \n",
    "                                    Gen.choicemap(T.obs_addr() => gt_voxelized_cloud, \n",
    "                                                :id => obj_id, \n",
    "                                                T.floating_pose_addr(1) => Pose(gt_position, orn))),\n",
    "                                    rotations_to_enumerate_over[:]);\n",
    "    \n",
    "        all_scored_traces = vcat(all_scored_traces, scored_traces)\n",
    "    end\n",
    "    return all_scored_traces\n",
    "    \n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d12e369",
   "metadata": {},
   "outputs": [],
   "source": [
    "function icp_move_no_unexplained(trace, i, inf_radius, renderer, cam_pose; iterations=10)\n",
    "    # get_cloud_func needs to give the points in the world frame\n",
    "#     get_cloud_func = (poses, ids, cam_pose) -> get_cloud_nocache([poses], [ids])  \n",
    "    get_cloud_func = (pose, id, cam_pose) -> get_cloud_func_cached(pose, id);\n",
    "\n",
    "    id = Gen.get_choices(trace)[:id]  \n",
    "    addr = T.floating_pose_addr(1)\n",
    "    \n",
    "    obs_cloud = T.move_points_to_frame_b(T.get_obs_cloud(trace), cam_pose)\n",
    "    c1_tree = NearestNeighbors.KDTree(obs_cloud);\n",
    "\n",
    "    refined_pose = trace[addr]\n",
    "    \n",
    "    refined_pose = T.icp_object_pose(\n",
    "        refined_pose,\n",
    "        obs_cloud,\n",
    "        p -> T.voxelize(get_cloud_func(p, id, cam_pose), v_resolution(inf_radius)),\n",
    "        c1_tree=c1_tree,\n",
    "        iterations=iterations\n",
    "    );\n",
    "\n",
    "    acceptances = false\n",
    "     \n",
    "    for _ in 1:iterations\n",
    "        trace, acc = T.pose_mixture_move(\n",
    "            trace, addr, [trace[addr], refined_pose], [0.5, 0.5], 1e-2, 5000.0\n",
    "        )\n",
    "        acceptances = acc || acceptances\n",
    "    end\n",
    "    \n",
    "    trace, acceptances, refined_pose\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1024d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Selecting from a set of traces over all enumerated angles, generate a set of initial particles\"\"\"\n",
    "Gen.@gen function generate_initial_pf_state_from_enum(scored_traces, num_particles, U=Gen.DynamicDSLTrace{Gen.DynamicDSLFunction{Any}})\n",
    "    # unpack traces\n",
    "    traces = (t -> t[1]).(scored_traces)\n",
    "    log_weights = (t -> t[1].score).(scored_traces)#(t -> t[2]).(scored_traces)  \n",
    "    \n",
    "    _, norm_log_weights = Gen.normalize_weights(log_weights)       \n",
    "    \n",
    "    # sample initial set of particles\n",
    "    selected_traces = Vector{Gen.DynamicDSLTrace{Gen.DynamicDSLFunction{Any}}}(undef, num_particles)\n",
    "    selected_log_weights = Vector{Float64}(undef, num_particles)\n",
    "    for i=1:num_particles\n",
    "        trace_idx = Gen.random(Gen.categorical, exp.(norm_log_weights))   \n",
    "        selected_traces[i] = traces[trace_idx]\n",
    "        selected_log_weights[i] = norm_log_weights[trace_idx]\n",
    "    end\n",
    "    \n",
    "    println(\"Initial particle state computed\"); flush(stdout)\n",
    "\n",
    "#     # visualize pdf of initial weights (?)\n",
    "#     plot(selected_log_weights, seriestype=:stephist, fmt = :png)\n",
    "    \n",
    "    # see intermediate results\n",
    "    top_n = min(5, num_particles-1)\n",
    "    _, norm_log_weights = Gen.normalize_weights(selected_log_weights)\n",
    "    p = sortperm(norm_log_weights)[end-top_n:end]; \n",
    "\n",
    "    best_trace = selected_traces[argmax(norm_log_weights)];\n",
    "    if vis\n",
    "        viz_trace(best_trace);\n",
    "    end\n",
    "    println(\"top$top_n traces:\")\n",
    "    for idx in p\n",
    "       println(\"curr_weight=\", norm_log_weights[idx], \" ori=\", R.params(Gen.get_retval(selected_traces[idx]).ori), \" id=\", Gen.get_retval(selected_traces[idx]).id) \n",
    "    end\n",
    "    flush(stdout)\n",
    "    \n",
    "    return Gen.ParticleFilterState{U}(selected_traces, Vector{U}(undef, num_particles), selected_log_weights, 0., collect(1:num_particles))\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bdf889",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Selecting from a set of traces over all enumerated angles, generate a set of initial particles\"\"\"\n",
    "Gen.@gen function generate_initial_pf_state(scored_traces, num_particles, U=Gen.DynamicDSLTrace{Gen.DynamicDSLFunction{Any}})\n",
    "    # unpack traces\n",
    "    traces = (t -> t[1]).(scored_traces)\n",
    "    log_weights = (t -> t[1].score).(scored_traces)#(t -> t[2]).(scored_traces)  \n",
    "    \n",
    "     _, norm_log_weights = Gen.normalize_weights(log_weights)    \n",
    "    flush(stdout)\n",
    "    \n",
    "    # sample initial set of particles\n",
    "    num_particles_per_obj = num_particles ÷ num_candidate_objs\n",
    "    selected_traces = Vector{Gen.DynamicDSLTrace{Gen.DynamicDSLFunction{Any}}}(undef, num_particles_per_obj * num_candidate_objs)\n",
    "    selected_log_weights = Vector{Float64}(undef, num_particles_per_obj * num_candidate_objs)\n",
    "        \n",
    "    stepsize = num_rotations_to_enumerate_over ÷ num_candidate_objs\n",
    "    \n",
    "    for i=0:num_candidate_objs-1  # TODO: Avoid globals\n",
    "        for j = 1:num_particles_per_obj\n",
    "            trace_idx = stepsize * i + \n",
    "                        Gen.random(Gen.categorical, \n",
    "                        exp.(Gen.normalize_weights(log_weights[stepsize*i+1:stepsize*(i+1)])[2]))   \n",
    "            selected_traces[num_particles_per_obj*i+j] = traces[trace_idx]\n",
    "            selected_log_weights[num_particles_per_obj*i+j] = norm_log_weights[trace_idx]\n",
    "        end        \n",
    "    end\n",
    "     \n",
    "    \n",
    "    println(\"Initial particle state computed ($num_particles_per_obj particles per object)\"); flush(stdout)\n",
    "\n",
    "    \n",
    "    # see intermediate results\n",
    "    top_n = min(10, num_particles-1)\n",
    "    _, norm_log_weights = Gen.normalize_weights(selected_log_weights)\n",
    "    p = sortperm(norm_log_weights)[end-top_n:end]; \n",
    "\n",
    "    best_trace = selected_traces[argmax(norm_log_weights)];\n",
    "    if vis\n",
    "        viz_trace(best_trace);\n",
    "    end\n",
    "    if topnprint\n",
    "        println(\"top$top_n traces:\")\n",
    "        for idx in p\n",
    "           println(\"curr_weight=\", norm_log_weights[idx], \" ori=\", R.params(Gen.get_retval(selected_traces[idx]).ori), \" id=\", Gen.get_retval(selected_traces[idx]).id) \n",
    "        end\n",
    "        flush(stdout)\n",
    "    end\n",
    "    \n",
    "    return Gen.ParticleFilterState{U}(selected_traces, Vector{U}(undef, num_particles), selected_log_weights, 0., collect(1:num_particles))\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725697ee",
   "metadata": {},
   "source": [
    "Note the parallelization via @Threads (there is no significant performance gain for this demo example (few objects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54354deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Overloads the Gen function\n",
    "Perform a particle filter update, where the model arguments are adjusted, new observations are added, \n",
    "and the default proposal is used for new latent state.\n",
    "\"\"\"\n",
    "function particle_filter_step!(state::Gen.ParticleFilterState{U}, new_args::Tuple, argdiffs::Tuple,\n",
    "        observations) where {U}    \n",
    "    log_incremental_weights = Vector{Float64}(undef, num_particles) \n",
    "    radius::Float64 = new_args[1]\n",
    "#     centroid::Vector{Float64} = new_args[end]\n",
    "    \n",
    "    @Threads.threads for i=1:num_particles\n",
    "    ## do mh, drift moves, etc. tune particle before update (i.e. new likelihood)\n",
    "        state.traces[i], acc, _ = icp_move_no_unexplained(state.traces[i], Gen.get_retval(state.traces[i]).id, \n",
    "                                            radius, renderer, camera_pose; iterations=15)\n",
    "\n",
    "        state.traces[i], acc = T.drift_move(state.traces[i], T.floating_pose_addr(1), 0.001, 100.0)\n",
    "        state.traces[i], acc = T.drift_move(state.traces[i], T.floating_pose_addr(1), 0.0005, 100.0)\n",
    "        state.traces[i], acc = T.drift_move(state.traces[i], T.floating_pose_addr(1), 0.0005, 500.0)\n",
    "        state.traces[i], acc = T.drift_move(state.traces[i], T.floating_pose_addr(1), 0.001, 1000.0)\n",
    "        state.traces[i], acc = T.drift_move(state.traces[i], T.floating_pose_addr(1), 0.0005, 1000.0)\n",
    "        \n",
    "        \n",
    "        # evolve the particle (with new radius involved in new_args)\n",
    "        (state.new_traces[i], increment, _, discard) = Gen.update(\n",
    "            state.traces[i], new_args, argdiffs, observations)\n",
    "#         if !isempty(discard)\n",
    "#             error(\"Choices were updated or deleted inside particle filter step: $discard\")\n",
    "#         end\n",
    "        log_incremental_weights[i] = increment\n",
    "        state.log_weights[i] += increment\n",
    "    end\n",
    "    \n",
    "    # swap references\n",
    "    tmp = state.traces\n",
    "    state.traces = state.new_traces\n",
    "    state.new_traces = tmp\n",
    "    \n",
    "    return log_incremental_weights\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc379a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Control rotation enumeration / update render cache\n",
    "\n",
    "unit_sphere_directions = T.fibonacci_sphere(60);\n",
    "other_rotation_angle = collect(0:0.24:(2*π));\n",
    "rotations_to_enumerate_over = [\n",
    "    let\n",
    "        T.geodesicHopf_select_axis(StaticArrays.SVector(dir...), ang, 1)\n",
    "    end\n",
    "    for dir in unit_sphere_directions, \n",
    "        ang in other_rotation_angle\n",
    "];\n",
    "@show num_rotations_to_enumerate_over = length(rotations_to_enumerate_over)\n",
    "dirs = hcat(unit_sphere_directions...)\n",
    "\n",
    "# cloud_lookup = generate_cloud_cache()\n",
    "# Serialization.serialize(\"render_caching_data.data\", (cloud_lookup, rotations_to_enumerate_over, unit_sphere_directions, other_rotation_angle, dirs))\n",
    "# @show length(cloud_lookup)\n",
    "\n",
    "(cloud_lookup, rotations_to_enumerate_over, unit_sphere_directions, other_rotation_angle, dirs) = \n",
    "Serialization.deserialize(\"render_caching_data_200_10.data\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee47e6a",
   "metadata": {},
   "source": [
    "#### Model & main particle filter function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8a68f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = (-100.0, 100.0, -100.0, 100.0,-100.0,300.0)\n",
    "\n",
    "# distance between two points on the pointcloud \n",
    "v_resolution = radius -> radius * 0.6   # TODO: experiment with relation btwn resolution and likelihood radius \n",
    "\n",
    "\"\"\"sample point clouds at the given camera resolution and radius\"\"\"\n",
    "Gen.@gen function model(radius, renderer, centroid, delta=0.9)\n",
    "    \n",
    "    # sample object id  \n",
    "    i = {:id} ~ Gen.uniform_discrete(first_candidate_obj, last_candidate_obj )\n",
    "\n",
    "    # sample pose\n",
    "    xc, yc, zc = centroid\n",
    "    p = {T.floating_pose_addr(1)} ~ T.uniformPose(xc-delta, xc+delta, yc-delta, yc+delta, zc-delta, zc+delta)\n",
    "#     gt_cloud = get_cloud_nocache([p], [i])    \n",
    "    gt_cloud = get_cloud_func_cached(p, i);\n",
    "\n",
    "    voxelized_cloud = GL.voxelize(gt_cloud, v_resolution(radius))\n",
    "    obs_cloud = {T.obs_addr()} ~ T.uniform_mixture_from_template(voxelized_cloud, 0.0001, radius, bounds)\n",
    "         \n",
    "    (id=i, pose=p, pos=p.pos, ori=p.orientation, cloud=gt_cloud, voxelized_cloud=voxelized_cloud, rendered_clouds=[voxelized_cloud], obs_cloud=obs_cloud)\n",
    "\n",
    "end\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486fd83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Particle filter on the evolution of agent knowledge over time; resolution control with radius\"\"\"\n",
    "function particle_filter(renderer, init_radius::Float64, final_radius::Float64, radius_step::Float64, scored_traces,\n",
    "                        gt_obj_id::Int, gt_pose::Pose, centroid, num_particles::Int, num_samples::Int, U=Gen.DynamicDSLTrace{Gen.DynamicDSLFunction{Any}})\n",
    "    \n",
    "    # initialize renderer and particle filter\n",
    "    GL.set_intrinsics!(renderer, camera)  \n",
    "#     gt_cloud = get_cloud_nocache([gt_pose], [gt_obj_id])\n",
    "    gt_cloud = get_cloud_func_cached(gt_pose, gt_obj_id)\n",
    "    gt_voxelized_cloud = GL.voxelize(gt_cloud, v_resolution(init_radius))\n",
    "    \n",
    "    println(\"\\ninitializing particle filter at radius $init_radius\") \n",
    "    flush(stdout)\n",
    "    \n",
    "    \n",
    "    # initialize a state of initial particles with various rotations  \n",
    "    state::Gen.ParticleFilterState{U} = generate_initial_pf_state(scored_traces, num_particles)\n",
    "\n",
    "    \n",
    "    # evolve over resolutions (modify sphere radius `r` of mixture point cloud likelihood)\n",
    "    @assert(radius_step < 0.0)\n",
    "    for radius in init_radius+radius_step:radius_step:final_radius-eps()\n",
    "        println(\"\\n========Radius=$radius========\"); flush(stdout)\n",
    "        Gen.maybe_resample!(state, ess_threshold=num_particles/3, verbose=true)  \n",
    "        \n",
    "        # update pf \n",
    "        gt_voxelized_cloud = GL.voxelize(gt_cloud, v_resolution(radius))\n",
    "        observations = Gen.choicemap(T.obs_addr() => gt_voxelized_cloud) \n",
    "        current_log_weights = particle_filter_step!(state, (radius, renderer, centroid),   \n",
    "                                                    (Gen.UnknownChange(),), observations)    \n",
    "        \n",
    "        # see intermediate results\n",
    "        top_n = min(5, num_particles-1)\n",
    "        _, norm_log_weights = Gen.normalize_weights(current_log_weights)\n",
    "        p = sortperm(norm_log_weights)[end-top_n:end]; \n",
    "        \n",
    "        best_trace = state.traces[argmax(norm_log_weights)];\n",
    "        \n",
    "        if vis\n",
    "            viz_trace(best_trace);\n",
    "        end\n",
    "        if topnprint\n",
    "            println(\"top$top_n traces:\")\n",
    "            for idx in p\n",
    "               println(\"weight=\", norm_log_weights[idx], \" ori=\", (Gen.get_retval(state.traces[idx]).ori)[1:3], \"  id=\", Gen.get_retval(state.traces[idx]).id) \n",
    "            end\n",
    "            flush(stdout)\n",
    "        end\n",
    "        \n",
    "    end;\n",
    "    \n",
    "    # normalize final weights\n",
    "    log_total_weight, norm_weights = Gen.normalize_weights(state.log_weights)\n",
    "    return [norm_weights, Gen.sample_unweighted_traces(state, num_samples)]\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271cb670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0001e938",
   "metadata": {},
   "source": [
    "### Conduct enumerative inference "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135a8303",
   "metadata": {},
   "source": [
    "Choose object to infer:\n",
    "\n",
    "(for pose-only inference, first = last = gt_id)\n",
    "(to add object id inference as well, specify the range of objects to consider with first_candidiate_obj and last_candidate_obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "270bbf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_candidate_obj = (last_candidate_obj = (gt_obj_id = rand(1:length(all_ids)))) = 14\n",
      "object = names[gt_obj_id] = \"025_mug\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"025_mug\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Choose gt object\n",
    "# enumerate between objects with id in range [first_candidate_obj, last_candidate_obj]\n",
    "\n",
    "@show first_candidate_obj = last_candidate_obj = gt_obj_id = rand(1:length(all_ids))  # choose some random obj\n",
    "num_candidate_objs = last_candidate_obj - first_candidate_obj + 1 #length(all_ids)\n",
    "@show object = names[gt_obj_id]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e07aaa",
   "metadata": {},
   "source": [
    "**Configure pf with parameters below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d18ae7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(true, false)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_particles_per_obj = 4  # note that few particles suffice\n",
    "num_particles = num_candidate_objs * num_particles_per_obj\n",
    "num_samples = num_particles  # number of samples to take from final pf state\n",
    "num_steps = 3\n",
    "final_radius = float(0.05)# low to high \"focus\"\n",
    "init_radius = float(0.30)  # high num = faster enum\n",
    "radius_step = (final_radius - init_radius)/num_steps\n",
    "\n",
    "topnprint, vis = true, false  # print info on top particles / meshcat viz top trace\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646f4fad",
   "metadata": {},
   "source": [
    "Choose pose to infer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ef6478a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_position = [gx, gy, gz] = [4.6714512685606895, 1.196984523316923, 3.574822720485526]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pose⟨pos=[4.6714512685606895, 1.196984523316923, 3.574822720485526], orientation=(w=0.314654989486088, x=-0.35006245304597583, y=-0.1153937694059694, z=0.8747186945191155)⟩"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Choose gt pose\n",
    "gx, gy, gz = Gen.uniform(0.0, 5.0), Gen.uniform(0.0, 5.0), Gen.uniform(0.0, 5.0)\n",
    "@show gt_position = [gx, gy, gz]\n",
    "tr, _ = Gen.generate(model, (init_radius, renderer, gt_position), Gen.choicemap(:id => gt_obj_id))\n",
    "gt_pose = T.Pose(pos=gt_position, orientation=Gen.get_retval(tr).ori)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1876876a",
   "metadata": {},
   "source": [
    "precompute enumeration; run the below code once and comment out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85fd6a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.737165 seconds (12.26 M allocations: 1.574 GiB, 10.51% gc time)\n"
     ]
    }
   ],
   "source": [
    "# gt_cloud = get_cloud_nocache([gt_pose], [gt_obj_id])\n",
    "gt_cloud = get_cloud_func_cached(gt_pose, gt_obj_id);\n",
    "gt_voxelized_cloud = GL.voxelize(gt_cloud, v_resolution(init_radius))\n",
    "\n",
    "# get centroid (at a finer resolution)\n",
    "centroid = T.centroid(GL.voxelize(gt_cloud, v_resolution(1e-10)))\n",
    "\n",
    "\n",
    "@time enum_ori_traces = precompute_enumerations(gt_voxelized_cloud, gt_pose, init_radius, renderer, \n",
    "    first_candidate_obj, last_candidate_obj, rotations_to_enumerate_over);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd3cadf",
   "metadata": {},
   "source": [
    "Run particle filter; generate traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7bee7488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n",
      "\n",
      "initializing particle filter at radius 0.3\n",
      "Initial particle state computed (4 particles per object)\n",
      "top3 traces:\n",
      "curr_weight=-2.8849486870087793 ori=[0.22707317975602864, 0.057981301976674074, 0.6382447120280401, 0.7332936841571869] id=14\n",
      "curr_weight=-1.156090624404329 ori=[0.2296872547160731, 0.04655991155938468, 0.600797663168104, 0.7642761984965394] id=14\n",
      "curr_weight=-1.156090624404329 ori=[0.2296872547160731, 0.04655991155938468, 0.600797663168104, 0.7642761984965394] id=14\n",
      "curr_weight=-1.156090624404329 ori=[0.2296872547160731, 0.04655991155938468, 0.600797663168104, 0.7642761984965394] id=14\n",
      "\n",
      "========Radius=0.21666666666666667========\n",
      "effective sample size: 3.3305024084235866, doing resample: false\n",
      "top3 traces:\n",
      "weight=-129.68751622818831 ori=[-0.866947388657898, 0.4348164226271651, -0.2435916745559366]  id=14\n",
      "weight=-52.31043668077344 ori=[-0.929531869239729, 0.3099574205679886, -0.19974208745914224]  id=14\n",
      "weight=-23.076319617823167 ori=[-0.9889929715722307, 0.14598194587147534, 0.02412827512077427]  id=14\n",
      "weight=-9.5077723472059e-11 ori=[-0.984674227915168, 0.16811988928412172, 0.04639361709071568]  id=14\n",
      "\n",
      "========Radius=0.13333333333333336========\n",
      "effective sample size: 1.0000000001901554, doing resample: true\n",
      "top3 traces:\n",
      "weight=-147.93447470587756 ori=[-0.9775865916092122, 0.2084042330850803, 0.029868571075632403]  id=14\n",
      "weight=-124.5050821931681 ori=[-0.984674227915168, 0.16811988928412172, 0.04639361709071568]  id=14\n",
      "weight=-101.7632122602858 ori=[-0.9850848677367949, 0.1595984680787502, 0.06431276967209577]  id=14\n",
      "weight=0.0 ori=[-0.974895375927046, 0.21512969237206, -0.05743014414020079]  id=14\n",
      "\n",
      "========Radius=0.05000000000000002========\n",
      "effective sample size: 1.0, doing resample: true\n",
      "top3 traces:\n",
      "weight=-289.471717309199 ori=[-0.9932505403178478, 0.03464058386693403, 0.11069505005939254]  id=14\n",
      "weight=-199.43028853180385 ori=[-0.9965531846255804, 0.0560385177722582, 0.06116726852240778]  id=14\n",
      "weight=-102.22338699038164 ori=[-0.9750446629279447, 0.2010227918393613, -0.09422177273241074]  id=14\n",
      "weight=0.0 ori=[-0.9972675970103522, 0.013622955715765314, 0.07260685250549857]  id=14\n",
      "  0.149777 seconds (1.22 M allocations: 158.246 MiB, 24.44% compilation time)\n"
     ]
    }
   ],
   "source": [
    "@time weights, pf_traces = particle_filter(renderer, init_radius, final_radius, radius_step,\n",
    "                                    enum_ori_traces, gt_obj_id, gt_pose, centroid, num_particles, num_samples);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a1c233",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "912f566b",
   "metadata": {},
   "source": [
    "### results\n",
    "Quantify the localization error (of the highest-weight trace); units are in centimeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd089b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pose_error (generic function with 1 method)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function pose_error(object_cloud, ground_truth_pose, predicted_pose)\n",
    "    tree = NearestNeighbors.KDTree(T.move_points_to_frame_b(object_cloud, predicted_pose))\n",
    "    _, dists = NearestNeighbors.nn(tree, T.move_points_to_frame_b(object_cloud, ground_truth_pose))\n",
    "    sum(dists) ./ length(dists) * 10    # scale to cm\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8bf15057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pose_error(obj_cloud, gt_pose, (Gen.get_retval(pf_traces[argmax(weights)])).pose) = 0.6080969466744001\n",
      "  0.603197 seconds (968.10 k allocations: 84.620 MiB, 95.76% compilation time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6080969466744001"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_cloud = id_to_cloud[gt_obj_id] \n",
    "\n",
    "@time @show pose_error(obj_cloud, gt_pose, (Gen.get_retval(pf_traces[argmax(weights)]).pose))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f31367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c027112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia multithreading6 1.7.2",
   "language": "julia",
   "name": "julia-multithreading6-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
